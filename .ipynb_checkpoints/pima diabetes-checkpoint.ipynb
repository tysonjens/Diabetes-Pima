{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, accuracy score\n",
    "%matplotlib inline  \n",
    "\n",
    "def violin_plot_binary(categorical_var, continuous_var, df):\n",
    "    # Draw a nested violinplot and split the violins for easier comparison\n",
    "    image = sns.violinplot(x=categorical_var, y=continuous_var, data=df, split=True,\n",
    "                   inner=\"quart\")\n",
    "    sns.despine(left=True)\n",
    "    return image\n",
    "\n",
    "def plotroc(FPR, TPR):\n",
    "    roc_auc = auc(FPR, TPR)\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(FPR, TPR, color='darkorange',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('img/ROCtree.png')\n",
    "    \n",
    "def try_lasso_hyperparam(X_train, y_train, X_test, y_test, params_to_try,):\n",
    "    aucs = []\n",
    "    for param in params_to_try:\n",
    "        mod = LogisticRegression(penalty='l1', C=param)\n",
    "        mod.fit(X_train, y_train)\n",
    "        y_test_preds = mod.predict_proba(X_test)[:,1]\n",
    "        aucs.append(roc_auc_score(y_test, y_test_preds))\n",
    "    return aucs\n",
    "\n",
    "def bootstrap_ci_coefficients(X_train, y_train, num_bootstraps):\n",
    "    X_train = X_train.values\n",
    "    y_train = y_train.values\n",
    "    bootstrap_estimates = []\n",
    "    for i in np.arange(num_bootstraps):\n",
    "        sample_index = np.random.choice(range(0, len(y_train)), len(y_train))\n",
    "        X_samples = X_train[sample_index]\n",
    "        y_samples = y_train[sample_index]\n",
    "        lm = LogisticRegression()\n",
    "        lm.fit(X_samples, y_samples)\n",
    "        bootstrap_estimates.append(lm.coef_[0])\n",
    "    bootstrap_estimates = np.asarray(bootstrap_estimates)\n",
    "    return bootstrap_estimates\n",
    "\n",
    "def plot_bootstrap_estimate(col_name_list, bootstrap_coefficient_array):\n",
    "    number_of_graphs = len(col_name_list)\n",
    "    fig, axes = plt.subplots(int((len(col_name_list)+1)/3),3, figsize=(10,10))\n",
    "    count = 0\n",
    "    for m, ax in zip(col_name_list, axes.flatten()):\n",
    "        ax.hist(bootstrap_coefficient_array[:,count], bins=30)\n",
    "        ax.set_title(m)\n",
    "        count += 1\n",
    "    return fig\n",
    "\n",
    "\n",
    "if __name__ = \"__main__\":\n",
    "    \n",
    "diab = pd.read_csv('data/diabetes.csv')\n",
    "\n",
    "diab.info()\n",
    "\n",
    "diab.describe()\n",
    "\n",
    "diab.columns\n",
    "\n",
    "pairplot = sns.pairplot(diab[['Outcome', \"Insulin\", \"BMI\", \"Age\"]][50:200])\n",
    "\n",
    "## print corr heat map\n",
    "sns.set(style=\"white\")\n",
    "# Compute the correlation matrix\n",
    "corr = diab.corr()\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns_plot = sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "\n",
    "\n",
    "glucimg = violin_plot_binary(\"Outcome\", \"Glucose\", diab)\n",
    "\n",
    "bmiimg = violin_plot_binary(\"Outcome\", \"BMI\", diab)\n",
    "\n",
    "\n",
    "######## Begin Models ##########\n",
    "\n",
    "X = diab.drop('Outcome', axis=1)\n",
    "y = diab['Outcome']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, stratify=y)\n",
    "\n",
    "\n",
    "mod_2 = LogisticRegression()\n",
    "mod_2.fit(X_train, y_train)\n",
    "y_test_preds2 = mod_2.predict_proba(X_test)[:,1]\n",
    "FPR_2, TPR_2, thresholds_2 = roc_curve(y_test, y_test_preds2)\n",
    "\n",
    "mod_2.coef_\n",
    "\n",
    "plotroc(FPR_2, TPR_2)\n",
    "\n",
    "\n",
    "params = np.linspace(.01,2,100)\n",
    "aucs = try_lasso_hyperparam(X_train, y_train, X_test, y_test, params)\n",
    "\n",
    "## Plot best tuning param\n",
    "figpt = plt.figure(figsize=(10,5))\n",
    "ax1 = figpt.add_subplot(111)\n",
    "ax1.plot(params, aucs)\n",
    "ax1.set_title('ROC-Area under curve for various hyperparameters \"C\"')\n",
    "ax1.set_ylabel('Area Under Curve')\n",
    "ax1.set_xlabel('Tuning Parameter \"C\"')\n",
    "\n",
    "\n",
    "bootstrapped_coefficients = bootstrap_ci_coefficients(X_train, y_train, 1000)\n",
    "\n",
    "bscoefs = plot_bootstrap_estimate(X_train.columns, bootstrapped_coefficients)\n",
    "\n",
    "\n",
    "## Model 2 - Decision Tree Method\n",
    "clf = tree.DecisionTreeClassifier(max_depth=5)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "cols = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
    "       'BMI', 'DiabetesPedigreeFunction', 'Age']\n",
    "\n",
    "diab_tree = tree.export_graphviz(clf, out_file=None, feature_names=cols, \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)  \n",
    "graph = graphviz.Source(diab_tree)  \n",
    "graph \n",
    "\n",
    "\n",
    "\n",
    "tree_preds = clf.predict_proba(X_test)[:,1]\n",
    "FPR_tree, TPR_tree, thresholds_tree = roc_curve(y_test, tree_preds)\n",
    "plotroc(FPR_tree, TPR_tree)\n",
    "\n",
    "## Model 3 - Gradient Boost\n",
    "\n",
    "\n",
    "grb = GradientBoostingClassifier()\n",
    "\n",
    "grb.fit(X_train, y_train)\n",
    "\n",
    "gbr_preds = rfor.predict_proba(X_test)[:,1]\n",
    "\n",
    "FPR_gbr, TPR_gbr, thresholds_gbr = roc_curve(y_test, gbr_preds)\n",
    "\n",
    "plotroc(FPR_gbr, TPR_gbr)\n",
    "\n",
    "## Grid Search\n",
    "\n",
    "gb_grid = {'learning_rate': [0.01, 0.1, 0.5, 1], \n",
    "                    'max_depth': [3, 2, None],\n",
    "                      'max_features': ['sqrt', 'log2', None],\n",
    "                      'min_samples_split': [2, 4],\n",
    "                      'min_samples_leaf': [1, 2, 4],\n",
    "                      'n_estimators': [10, 20, 40, 80],\n",
    "                      'random_state': [1]}\n",
    "\n",
    "gb_gridsearch = GridSearchCV(GradientBoostingClassifier(),\n",
    "                             gb_grid,\n",
    "                             n_jobs=-1,\n",
    "                             verbose=True,\n",
    "                             scoring='roc_auc')\n",
    "gb_gridsearch.fit(X_train, y_train)\n",
    "\n",
    "print (\"best parameters:\", gb_gridsearch.best_params_)\n",
    "\n",
    "best_gb_model = gb_gridsearch.best_estimator_\n",
    "\n",
    "best_gb_model.fit(X_train, y_train);\n",
    "\n",
    "gbrbest = best_gb_model.predict_proba(X_test)[:,1]\n",
    "FPR_gbrbest, TPR_gbrbest, thresholds_gbrbest = roc_curve(y_test, gbrbest)\n",
    "plotroc(FPR_gbrbest, TPR_gbrbest)\n",
    "\n",
    "np.mean(cross_val_score(best_gb_model, X_train, y_train, scoring='accuracy'))\n",
    "\n",
    "y_preds_gbr = best_gb_model.predict(X_test)\n",
    "\n",
    "y_preds_tree = clf.predict(X_test)\n",
    "\n",
    "y_preds_mod2 = mod_2.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, y_preds_gbr)\n",
    "\n",
    "accuracy_score(y_test, y_preds_tree)\n",
    "\n",
    "accuracy_score(y_test, y_preds_mod2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
